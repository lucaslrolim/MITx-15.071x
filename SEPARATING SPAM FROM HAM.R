emails = read.csv("./data/emails.csv",stringsAsFactors = FALSE)
nrow(emails)
sum(emails$spam)
t_cha = lapply(emails$text,nchar)
nchar(emails$text[which.max(t_cha)])
which.min(nchar(emails$text))
library(tm)
corpus = Corpus(VectorSource(emails$text))
corpus = tm_map(corpus,content_transformer(tolower))
corpus = tm_map(corpus,removePunctuation)
corpus = tm_map(corpus,removeWords,stopwords("english"))
corpus = tm_map(corpus,stemDocument)
dtm = DocumentTermMatrix(corpus)
ncol(dtm)
dtm= removeSparseTerms(dtm,0.95)
ncol(dtm)
emailsSparse = as.data.frame(as.matrix(dtm))
w_sum = lapply(emailsSparse,sum)
w_sum[which.max(w_sum)]
emailsSparse$spam = emails$spam
hamEmails = subset(emailsSparse,emailsSparse$spam == 0)
sum(as.numeric(colSums(hamEmails) >= 5000))
spamEmails = subset(emailsSparse,emailsSparse$spam == 1)
# Ignore "spam" because it's dependent variable
sum(as.numeric(colSums(spamEmails) >= 1000))
emailsSparse$spam = as.factor(emailsSparse$spam)
set.seed(123)
library(caTools)
spl = sample.split(emailsSparse,SplitRatio = 0.7)
train = subset(emailsSparse,spl=TRUE)
test = subset(emailsSparse,spl = FALSE)
library(rpart)
library(rpart.plot)
# Logistic Regression Model
spamLog = glm(spam ~ ., data=train, family="binomial")
# Cross Validation Model
spamCART = rpart(spam ~ ., data=train, method="class")
# Random Forest Model
library(randomForest)
spamRf = randomForest(spam ~.,data=train)
# Predictions
predictSpamLog = predict(spamLog,data=train, type="response")
predictSpamCART = predict(spamCART ,data=train)[,2]
predictSpamRf = predict(spamRf ,data=train, type="prob")
sum(predictSpamLog < 0.00001)
sum(predictSpamLog > 0.99999)
sum((predictSpamLog <= 0.99999) & (predictSpamLog >= 0.00001))
summary(spamLog)
prp(spamCART)
table(train$spam, predictSpamLog >0.5)